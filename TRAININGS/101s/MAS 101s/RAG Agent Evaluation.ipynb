{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T12:58:34.526586Z",
     "start_time": "2025-12-18T12:58:23.752042Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow import log_params, log_metrics\n",
    "from typing import List, Dict, TypedDict\n",
    "\n",
    "# LangChain & AI Imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangGraph Imports\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# Ragas Imports\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Ragas Generation Imports (Necessary for Step 3)\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:00:37.106136Z",
     "start_time": "2025-12-18T13:00:37.057979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "8c14e52e3f36aab2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "PDF_PATH = \"xx.pdf\"\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"dspy_book_collection\""
   ],
   "id": "b2d6e73ad3e1dc7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:02:51.599603Z",
     "start_time": "2025-12-18T13:02:48.917295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Global Models\n",
    "llm_engine = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embedding_engine = OpenAIEmbeddings( model=\"text-embedding-3-large\")\n",
    "\n",
    "lm_judge = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    ")"
   ],
   "id": "14de4c6eb0fcc55d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:03:28.208181Z",
     "start_time": "2025-12-18T13:03:28.200379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Step 1 & 2: Extract & Vectorize (Chroma)\n",
    "# ==========================================\n",
    "def process_and_vectorize_pdf(file_path: str, persist_dir: str, collection_name: str = COLLECTION_NAME):\n",
    "    \"\"\"Loads PDF, splits, and saves to ChromaDB.\"\"\"\n",
    "    print(f\"--- Loading {file_path} ---\")\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load() # Defaults to page-by-page chunking\n",
    "\n",
    "    print(f\"--- Vectorizing {len(documents)} pages to ChromaDB ---\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_engine,\n",
    "        collection_name = collection_name,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    return vectorstore, documents"
   ],
   "id": "60fafa952a73c472",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:22.867574Z",
     "start_time": "2025-12-18T13:05:59.617718Z"
    }
   },
   "cell_type": "code",
   "source": "chromaVectorStore, langchainDocLs = process_and_vectorize_pdf(\"complete-book.pdf\", \"./chroma_db\")",
   "id": "919733742b70157f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading complete-book.pdf ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vectorizing 254 pages to ChromaDB ---\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:44.538045Z",
     "start_time": "2025-12-18T13:06:44.527975Z"
    }
   },
   "cell_type": "code",
   "source": "len(langchainDocLs)",
   "id": "d1f0c3dca515d582",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:57.467595Z",
     "start_time": "2025-12-18T13:06:57.458088Z"
    }
   },
   "cell_type": "code",
   "source": "langchainDocLs[108]",
   "id": "b02fc5cf026872f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'creator': '', 'creationdate': '2025-12-14T17:21:32+05:00', 'title': 'Untitled', 'moddate': '2025-12-14T17:21:29+05:00', 'source': 'complete-book.pdf', 'total_pages': 254, 'page': 108, 'page_label': '108'}, page_content='Integrating DSPy with MCP Server\\nPlaywright is an open-source automation framework created by Microsoft for\\nprogrammatic browser control. It allows you to automate actions in modern\\nbrowsers like Chromium (Chrome, Edge), Firefox, and WebKit (Safari) across\\nWindows, macOS, and Linux. The playwright-mcp package is an MCP server that\\nexposes tools for browser control.\\nPlaywright MCP Repository - https://github.com/microsoft/playwright-mcp\\nLet us run the Playwright MCP Server.\\nInstalling playwright MCP Server\\n$ npx @playwright/mcp@latest --port 8931\\nListening on http://localhost:8931\\nPut this in your client config:\\n{\\n\\xa0 \"mcpServers\": {\\n\\xa0   \"playwright\": {\\n\\xa0     \"url\": \"http://localhost:8931/mcp\"\\n\\xa0   }\\n\\xa0 }\\n}\\n\\uf0eb\\nInstructions for installing nvm to manage Node.js and npx can be\\nfound at https://github.com/nvm-sh/nvm?tab=readme-ov-file#\\ninstalling-and-updating\\n\\uf06a\\nThis chapter assumes familiarity with event loop concepts and\\nasync/await patterns. If you are unfamiliar with these topics,\\nspend some time understanding the basics at\\nhttps://docs.python.org/3/howto/a-conceptual-overview-of-\\nasyncio.html#a-conceptual-overview-of-asyncio. Only the section\\ntitled \"A conceptual overview part 1: the high-level\" is\\nrequired.\\n108')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:11:03.295692Z",
     "start_time": "2025-12-18T13:11:03.279749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Step 3: Generate Synthetic Test Sets\n",
    "# ==========================================\n",
    "def save_for_dspy(testset_df: pd.DataFrame, filename: str):\n",
    "    \"\"\"Saves Ragas testset in DSPy-compatible JSON format.\"\"\"\n",
    "    dspy_data = []\n",
    "    for _, row in testset_df.iterrows():\n",
    "        entry = {\n",
    "            \"question\": row['user_input'],\n",
    "            \"answer\": row['reference'],\n",
    "            \"gold_context\": row['reference_contexts'],\n",
    "            \"metadata\": {\"synthesizer\": row.get('synthesizer_name', 'unknown')}\n",
    "        }\n",
    "        dspy_data.append(entry)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dspy_data, f, indent=4)\n",
    "    print(f\"Saved DSPy dataset: {filename}\")\n",
    "\n",
    "def generate_ragas_testsets(documents):\n",
    "    \"\"\"Generates Single, Multi-hop, and Mixed test sets.\"\"\"\n",
    "    print(\"--- Initializing Ragas Testset Generator ---\")\n",
    "\n",
    "    # Wrappers for Ragas\n",
    "    generator_llm = LangchainLLMWrapper(llm_engine)\n",
    "    generator_embeddings = LangchainEmbeddingsWrapper(embedding_engine)\n",
    "\n",
    "    generator = TestsetGenerator(\n",
    "        llm=generator_llm,\n",
    "        embedding_model=generator_embeddings\n",
    "    )\n",
    "\n",
    "    # Define Synthesizer Distributions\n",
    "    distributions = {\n",
    "        \"single_hop\": [\n",
    "            (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0)\n",
    "        ],\n",
    "        \"multi_hop\": [\n",
    "            (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "            (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.5)\n",
    "        ],\n",
    "        \"mixed\": [\n",
    "            (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "            (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "            (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    test_size = 5  # Small size for demo; increase for production\n",
    "\n",
    "\n",
    "    datasetLs = []\n",
    "    dataFrameLs = []\n",
    "    for name, dist in distributions.items():\n",
    "        print(f\"Generating {name} testset...\")\n",
    "        testset = generator.generate_with_langchain_docs(\n",
    "            documents,\n",
    "            testset_size=test_size,\n",
    "            query_distribution=dist\n",
    "        )\n",
    "\n",
    "        df = testset.to_pandas()\n",
    "        save_for_dspy(df, f\"ragas_testset_{name}.json\")\n",
    "        datasetLs.append(testset)\n",
    "        dataFrameLs.append(df)\n",
    "\n",
    "    return datasetLs, dataFrameLs"
   ],
   "id": "34a5f6a1e6cfd6e1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-18T13:11:58.114775Z"
    }
   },
   "cell_type": "code",
   "source": "synthethicDatasetLs, datasetDFLs = generate_ragas_testsets(langchainDocLs)",
   "id": "65b9154c37ee9a78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Ragas Testset Generator ---\n",
      "Generating single_hop testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\934105838.py:25: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(llm_engine)\n",
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\934105838.py:26: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  generator_embeddings = LangchainEmbeddingsWrapper(embedding_engine)\n",
      "Applying SummaryExtractor: 100%|██████████| 239/239 [16:43<00:00,  4.20s/it]\n",
      "Applying CustomNodeFilter:   0%|          | 0/254 [00:00<?, ?it/s]Node acda5c8a-482f-424a-9c3b-3b1de4ca33f4 does not have a summary. Skipping filtering.\n",
      "Node 75baf941-8f13-4777-a5e3-6ebd2f151b63 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   1%|          | 2/254 [00:03<08:08,  1.94s/it]Node 54d0e0fe-b396-4fb3-a48e-4ff2b493a536 does not have a summary. Skipping filtering.\n",
      "Node 12c52ff6-be56-4e74-90f6-c8529827c531 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 56/254 [02:28<06:37,  2.01s/it]Node 43e92e72-cf72-4e1c-a412-83fd22bb625a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  29%|██▉       | 74/254 [03:15<06:02,  2.01s/it]Node fc1bb5f6-ad32-4bb7-b9eb-7bd4c5bbd888 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  36%|███▌      | 92/254 [04:05<05:36,  2.08s/it]Node c46f58a8-92c9-46d3-a4ed-1599689bacc6 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 109/254 [04:42<04:16,  1.77s/it]Node 1ce2716c-2d7a-43e8-bf0b-a32d44376bd6 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 110/254 [04:45<04:22,  1.82s/it]Node 15f9ef32-73fc-4775-8431-fc84e31e35fa does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████     | 129/254 [05:21<03:19,  1.59s/it]Node b9a064e6-59b6-4288-b57d-8132bbf4cb4a does not have a summary. Skipping filtering.\n",
      "Node b977ab3d-3fec-4cbd-ad27-d325516b5728 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  85%|████████▌ | 216/254 [08:23<01:04,  1.70s/it]Node 58fda2a6-2447-4475-b319-8c9903426a22 does not have a summary. Skipping filtering.\n",
      "Node 320a0345-a80e-4dc1-978d-9afda4748de8 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  93%|█████████▎| 235/254 [09:02<00:30,  1.61s/it]Node 5ccb828f-3c5b-4212-803a-82f48be14bed does not have a summary. Skipping filtering.\n",
      "Node 2dadc5c8-23da-4b53-92ea-1420ecf9d477 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter: 100%|██████████| 254/254 [09:41<00:00,  2.29s/it]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 239/239 [04:44<00:00,  1.19s/it]\n",
      "Applying ThemesExtractor: 100%|██████████| 254/254 [09:34<00:00,  2.26s/it]\n",
      "Applying NERExtractor: 100%|██████████| 254/254 [09:32<00:00,  2.25s/it]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:06<00:00,  2.33s/it]\n",
      "Generating Scenarios: 100%|██████████| 1/1 [00:33<00:00, 33.30s/it]\n",
      "Generating Samples: 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DSPy dataset: ragas_testset_single_hop.json\n",
      "Generating multi_hop testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  57%|█████▋    | 137/239 [05:23<02:57,  1.74s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# Step 4a: Define LangGraph RAG Agent\n",
    "# ==========================================\n",
    "\n",
    "# Define State\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def build_rag_graph(vectorstore):\n",
    "    \"\"\"Builds the compiled LangGraph workflow.\"\"\"\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    # Node 1: Retrieve\n",
    "    def retrieve(state: GraphState):\n",
    "        print(f\"Retrieving for: {state['question']}\")\n",
    "        docs = retriever.invoke(state[\"question\"])\n",
    "        return {\"context\": docs}\n",
    "\n",
    "    # Node 2: Generate\n",
    "    def generate(state: GraphState):\n",
    "        print(\"Generating answer...\")\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Answer the question based only on the following context:\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Format context into a single string for the prompt\n",
    "        context_text = \"\\n\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
    "\n",
    "        chain = prompt | llm_engine | StrOutputParser()\n",
    "        response = chain.invoke({\"context\": context_text, \"question\": state[\"question\"]})\n",
    "\n",
    "        return {\"answer\": response}\n",
    "\n",
    "    # Build Graph\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"retrieve\", retrieve)\n",
    "    workflow.add_node(\"generate\", generate)\n",
    "\n",
    "    workflow.add_edge(START, \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "# ==========================================\n",
    "# Step 4b: Evaluate with Ragas & MLflow\n",
    "# ==========================================\n",
    "def evaluate_langgraph_agent(app, testsets_generator):\n",
    "    \"\"\"Evaluates the LangGraph app using Ragas and logs to MLflow.\"\"\"\n",
    "\n",
    "    # Ragas Metrics\n",
    "    metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "\n",
    "    # Iterate over generated testsets\n",
    "    for name, test_df in testsets_generator:\n",
    "        print(f\"\\n--- Evaluating Testset: {name} ---\")\n",
    "\n",
    "        # Start MLflow Run\n",
    "        with mlflow.start_run(run_name=f\"RAG_Eval_{name}\"):\n",
    "            log_params({\"testset_type\": name, \"model\": \"gpt-4o\", \"vector_db\": \"Chroma\"})\n",
    "\n",
    "            questions = test_df['user_input'].tolist()\n",
    "            ground_truths = test_df['reference'].tolist()\n",
    "\n",
    "            answers = []\n",
    "            contexts = []\n",
    "\n",
    "            # Run Inference\n",
    "            for q in questions:\n",
    "                # Invoke LangGraph\n",
    "                result = app.invoke({\"question\": q})\n",
    "\n",
    "                answers.append(result[\"answer\"])\n",
    "                # Extract page content for Ragas\n",
    "                retrieved_texts = [doc.page_content for doc in result[\"context\"]]\n",
    "                contexts.append(retrieved_texts)\n",
    "\n",
    "            # Prepare Ragas Dataset\n",
    "            eval_data = {\n",
    "                \"question\": questions,\n",
    "                \"answer\": answers,\n",
    "                \"contexts\": contexts,\n",
    "                \"ground_truth\": ground_truths\n",
    "            }\n",
    "            dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "            # Run Evaluation\n",
    "            results = evaluate(\n",
    "                dataset,\n",
    "                metrics=metrics,\n",
    "                llm=LangchainLLMWrapper(llm_engine),\n",
    "                embeddings=LangchainEmbeddingsWrapper(embedding_engine)\n",
    "            )\n",
    "\n",
    "            print(f\"Results for {name}: {results}\")\n",
    "\n",
    "            # Log Metrics to MLflow\n",
    "            for metric_name, score in results.items():\n",
    "                log_metrics({metric_name: score})\n",
    "\n",
    "            # Save CSV artifact\n",
    "            csv_name = f\"eval_results_{name}.csv\"\n",
    "            results.to_pandas().to_csv(csv_name, index=False)\n",
    "            mlflow.log_artifact(csv_name)\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(PDF_PATH):\n",
    "        # 1. Setup Data\n",
    "        vectorstore, documents = process_and_vectorize_pdf(PDF_PATH, CHROMA_PERSIST_DIR)\n",
    "\n",
    "        # 2. Build LangGraph Agent\n",
    "        rag_app = build_rag_graph(vectorstore)\n",
    "\n",
    "        # 3. Generate & Evaluate\n",
    "        # Note: generate_ragas_testsets yields (name, df) tuples\n",
    "        evaluate_langgraph_agent(rag_app, generate_ragas_testsets(documents))\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: File {PDF_PATH} not found.\")"
   ],
   "id": "c10902f8814b0524"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
