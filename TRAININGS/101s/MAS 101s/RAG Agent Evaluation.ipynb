{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T19:12:40.318275Z",
     "start_time": "2025-12-18T19:12:40.310973Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow import log_params, log_metrics\n",
    "from typing import List, Dict, TypedDict\n",
    "\n",
    "# LangChain & AI Imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from typing import List, Literal, TypedDict\n",
    "\n",
    "# LangGraph Imports\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# Ragas Imports\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Ragas Generation Imports (Necessary for Step 3)\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:00:37.106136Z",
     "start_time": "2025-12-18T13:00:37.057979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "8c14e52e3f36aab2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "PDF_PATH = \"xx.pdf\"\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"dspy_book_collection\""
   ],
   "id": "b2d6e73ad3e1dc7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:02:51.599603Z",
     "start_time": "2025-12-18T13:02:48.917295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Global Models\n",
    "llm_engine = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embedding_engine = OpenAIEmbeddings( model=\"text-embedding-3-large\")\n",
    "\n",
    "lm_judge = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    ")"
   ],
   "id": "14de4c6eb0fcc55d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.Vectorizing the Knowledge Base",
   "id": "abfc609a393171dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:03:28.208181Z",
     "start_time": "2025-12-18T13:03:28.200379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Step 1 & 2: Extract & Vectorize (Chroma)\n",
    "# ==========================================\n",
    "def process_and_vectorize_pdf(file_path: str, persist_dir: str, collection_name: str = COLLECTION_NAME):\n",
    "    \"\"\"Loads PDF, splits, and saves to ChromaDB.\"\"\"\n",
    "    print(f\"--- Loading {file_path} ---\")\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load() # Defaults to page-by-page chunking\n",
    "\n",
    "    print(f\"--- Vectorizing {len(documents)} pages to ChromaDB ---\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_engine,\n",
    "        collection_name = collection_name,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    return vectorstore, documents"
   ],
   "id": "60fafa952a73c472",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:22.867574Z",
     "start_time": "2025-12-18T13:05:59.617718Z"
    }
   },
   "cell_type": "code",
   "source": "chromaVectorStore, langchainDocLs = process_and_vectorize_pdf(\"complete-book.pdf\", \"./chroma_db\")",
   "id": "919733742b70157f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading complete-book.pdf ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n",
      "Got invalid hex string: Odd-length string (b'1f5a5')\n",
      "Got invalid hex string: Odd-length string (b'1f4e6')\n",
      "Got invalid hex string: Odd-length string (b'1f517')\n",
      "Got invalid hex string: Odd-length string (b'1f4da')\n",
      "Got invalid hex string: Odd-length string (b'1f680')\n",
      "Got invalid hex string: Odd-length string (b'1f3a7')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vectorizing 254 pages to ChromaDB ---\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:44.538045Z",
     "start_time": "2025-12-18T13:06:44.527975Z"
    }
   },
   "cell_type": "code",
   "source": "len(langchainDocLs)",
   "id": "d1f0c3dca515d582",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:57.467595Z",
     "start_time": "2025-12-18T13:06:57.458088Z"
    }
   },
   "cell_type": "code",
   "source": "langchainDocLs[108]",
   "id": "b02fc5cf026872f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'creator': '', 'creationdate': '2025-12-14T17:21:32+05:00', 'title': 'Untitled', 'moddate': '2025-12-14T17:21:29+05:00', 'source': 'complete-book.pdf', 'total_pages': 254, 'page': 108, 'page_label': '108'}, page_content='Integrating DSPy with MCP Server\\nPlaywright is an open-source automation framework created by Microsoft for\\nprogrammatic browser control. It allows you to automate actions in modern\\nbrowsers like Chromium (Chrome, Edge), Firefox, and WebKit (Safari) across\\nWindows, macOS, and Linux. The playwright-mcp package is an MCP server that\\nexposes tools for browser control.\\nPlaywright MCP Repository - https://github.com/microsoft/playwright-mcp\\nLet us run the Playwright MCP Server.\\nInstalling playwright MCP Server\\n$ npx @playwright/mcp@latest --port 8931\\nListening on http://localhost:8931\\nPut this in your client config:\\n{\\n\\xa0 \"mcpServers\": {\\n\\xa0   \"playwright\": {\\n\\xa0     \"url\": \"http://localhost:8931/mcp\"\\n\\xa0   }\\n\\xa0 }\\n}\\n\\uf0eb\\nInstructions for installing nvm to manage Node.js and npx can be\\nfound at https://github.com/nvm-sh/nvm?tab=readme-ov-file#\\ninstalling-and-updating\\n\\uf06a\\nThis chapter assumes familiarity with event loop concepts and\\nasync/await patterns. If you are unfamiliar with these topics,\\nspend some time understanding the basics at\\nhttps://docs.python.org/3/howto/a-conceptual-overview-of-\\nasyncio.html#a-conceptual-overview-of-asyncio. Only the section\\ntitled \"A conceptual overview part 1: the high-level\" is\\nrequired.\\n108')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "### 2. Generating Synthetic Dataset",
   "id": "8c3aa7bdbddd6ae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T18:04:26.472800Z",
     "start_time": "2025-12-18T18:04:26.464533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Step 3: Generate Synthetic Test Sets\n",
    "# ==========================================\n",
    "def save_for_dspy(testset_df: pd.DataFrame, filename: str):\n",
    "    \"\"\"Saves Ragas testset in DSPy-compatible JSON format.\"\"\"\n",
    "    dspy_data = []\n",
    "    for _, row in testset_df.iterrows():\n",
    "        entry = {\n",
    "            \"question\": row['user_input'],\n",
    "            \"answer\": row['reference'],\n",
    "            \"gold_context\": row['reference_contexts'],\n",
    "            \"metadata\": {\"synthesizer\": row.get('synthesizer_name', 'unknown')}\n",
    "        }\n",
    "        dspy_data.append(entry)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dspy_data, f, indent=4)\n",
    "    print(f\"Saved DSPy dataset: {filename}\")\n",
    "\n",
    "def generate_ragas_testsets(documents, num_of_questions = 100):\n",
    "    \"\"\"Generates Single, Multi-hop, and Mixed test sets.\"\"\"\n",
    "    print(\"--- Initializing Ragas Testset Generator ---\")\n",
    "\n",
    "    # Wrappers for Ragas\n",
    "    generator_llm = LangchainLLMWrapper(llm_engine)\n",
    "    generator_embeddings = LangchainEmbeddingsWrapper(embedding_engine)\n",
    "\n",
    "    generator = TestsetGenerator(\n",
    "        llm=generator_llm,\n",
    "        embedding_model=generator_embeddings\n",
    "    )\n",
    "\n",
    "    # Define Synthesizer Distributions\n",
    "    distributions = {\n",
    "        \"single_hop\": [\n",
    "            (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    '''\n",
    "        \"multi_hop\": [\n",
    "            (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "            (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.5)\n",
    "        ],\n",
    "        \"mixed\": [\n",
    "            (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "            (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "            (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25)\n",
    "        ]\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    test_size = num_of_questions  # Small size for demo; increase for production\n",
    "\n",
    "\n",
    "    datasetLs = []\n",
    "    dataFrameLs = []\n",
    "    for name, dist in distributions.items():\n",
    "        print(f\"Generating {name} testset...\")\n",
    "        testset = generator.generate_with_langchain_docs(\n",
    "            documents,\n",
    "            testset_size=test_size,\n",
    "            query_distribution=dist\n",
    "        )\n",
    "\n",
    "        df = testset.to_pandas()\n",
    "        save_for_dspy(df, f\"ragas_testset_{name}.json\")\n",
    "        datasetLs.append(testset)\n",
    "        dataFrameLs.append(df)\n",
    "\n",
    "    return datasetLs, dataFrameLs"
   ],
   "id": "34a5f6a1e6cfd6e1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:07:41.426463Z",
     "start_time": "2025-12-18T18:04:27.281426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Generate single dataset\n",
    "synthethicDatasetLs, datasetDFLs = generate_ragas_testsets(langchainDocLs)"
   ],
   "id": "a2823432fea850ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\1298520239.py:25: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(llm_engine)\n",
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\1298520239.py:26: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  generator_embeddings = LangchainEmbeddingsWrapper(embedding_engine)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Ragas Testset Generator ---\n",
      "Generating single_hop testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor: 100%|██████████| 239/239 [09:58<00:00,  2.50s/it]\n",
      "Applying CustomNodeFilter:   0%|          | 0/254 [00:00<?, ?it/s]Node 2f9962cb-f417-4612-ba72-9679f36806f9 does not have a summary. Skipping filtering.\n",
      "Node 691bd0a0-d788-4aa8-8c21-c61a5f24bf58 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   1%|          | 2/254 [00:02<06:16,  1.49s/it]Node 66748b17-b084-4733-b2fa-b702dfcafb47 does not have a summary. Skipping filtering.\n",
      "Node 37ff9cdd-7749-46e1-a09a-12a5b8d1de2f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 56/254 [02:03<06:22,  1.93s/it]Node 72704681-de1d-4699-8b8d-7814797a0508 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  29%|██▉       | 74/254 [02:52<06:03,  2.02s/it]Node b3b3735e-ae14-43ec-915c-121ede5be1d4 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  36%|███▌      | 92/254 [03:40<05:30,  2.04s/it]Node d48325af-2448-4c4e-b048-e057bfc63527 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 109/254 [04:26<04:50,  2.01s/it]Node 4952458c-68de-4973-ae4f-2debe3632ba3 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  44%|████▍     | 112/254 [04:35<05:04,  2.14s/it]Node 69c84a6a-7804-491e-ac9b-9ddcbc555dea does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████     | 129/254 [05:21<04:33,  2.19s/it]Node 08dbe310-17f3-4bee-b1c6-6939f9f63ad7 does not have a summary. Skipping filtering.\n",
      "Node 43251ee1-d94d-4798-81a5-81e0a9d15b09 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  85%|████████▍ | 215/254 [09:23<01:27,  2.24s/it]Node f0db820b-4cf3-40bf-b698-0160ffcdecc9 does not have a summary. Skipping filtering.\n",
      "Node 8c60fdf3-70a7-4cab-899b-73901e3a8d65 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  92%|█████████▏| 234/254 [10:13<00:41,  2.08s/it]Node 551493a8-826d-4338-813b-b21c07080ba6 does not have a summary. Skipping filtering.\n",
      "Node bfc273e6-4653-4e18-878e-eb9ec3bdc61a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter: 100%|██████████| 254/254 [11:05<00:00,  2.62s/it]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 239/239 [05:47<00:00,  1.45s/it]\n",
      "Applying ThemesExtractor: 100%|██████████| 254/254 [12:08<00:00,  2.87s/it]\n",
      "Applying NERExtractor: 100%|██████████| 254/254 [10:02<00:00,  2.37s/it]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:09<00:00,  3.20s/it]\n",
      "Generating Scenarios: 100%|██████████| 1/1 [09:14<00:00, 554.41s/it]\n",
      "Generating Samples: 100%|██████████| 100/100 [04:45<00:00,  2.86s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DSPy dataset: ragas_testset_single_hop.json\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:35:02.335838Z",
     "start_time": "2025-12-18T13:11:58.114775Z"
    }
   },
   "cell_type": "code",
   "source": "synthethicDatasetLs, datasetDFLs = generate_ragas_testsets(langchainDocLs)",
   "id": "65b9154c37ee9a78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Ragas Testset Generator ---\n",
      "Generating single_hop testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\934105838.py:25: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(llm_engine)\n",
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_55856\\934105838.py:26: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  generator_embeddings = LangchainEmbeddingsWrapper(embedding_engine)\n",
      "Applying SummaryExtractor: 100%|██████████| 239/239 [16:43<00:00,  4.20s/it]\n",
      "Applying CustomNodeFilter:   0%|          | 0/254 [00:00<?, ?it/s]Node acda5c8a-482f-424a-9c3b-3b1de4ca33f4 does not have a summary. Skipping filtering.\n",
      "Node 75baf941-8f13-4777-a5e3-6ebd2f151b63 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   1%|          | 2/254 [00:03<08:08,  1.94s/it]Node 54d0e0fe-b396-4fb3-a48e-4ff2b493a536 does not have a summary. Skipping filtering.\n",
      "Node 12c52ff6-be56-4e74-90f6-c8529827c531 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 56/254 [02:28<06:37,  2.01s/it]Node 43e92e72-cf72-4e1c-a412-83fd22bb625a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  29%|██▉       | 74/254 [03:15<06:02,  2.01s/it]Node fc1bb5f6-ad32-4bb7-b9eb-7bd4c5bbd888 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  36%|███▌      | 92/254 [04:05<05:36,  2.08s/it]Node c46f58a8-92c9-46d3-a4ed-1599689bacc6 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 109/254 [04:42<04:16,  1.77s/it]Node 1ce2716c-2d7a-43e8-bf0b-a32d44376bd6 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 110/254 [04:45<04:22,  1.82s/it]Node 15f9ef32-73fc-4775-8431-fc84e31e35fa does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████     | 129/254 [05:21<03:19,  1.59s/it]Node b9a064e6-59b6-4288-b57d-8132bbf4cb4a does not have a summary. Skipping filtering.\n",
      "Node b977ab3d-3fec-4cbd-ad27-d325516b5728 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  85%|████████▌ | 216/254 [08:23<01:04,  1.70s/it]Node 58fda2a6-2447-4475-b319-8c9903426a22 does not have a summary. Skipping filtering.\n",
      "Node 320a0345-a80e-4dc1-978d-9afda4748de8 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  93%|█████████▎| 235/254 [09:02<00:30,  1.61s/it]Node 5ccb828f-3c5b-4212-803a-82f48be14bed does not have a summary. Skipping filtering.\n",
      "Node 2dadc5c8-23da-4b53-92ea-1420ecf9d477 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter: 100%|██████████| 254/254 [09:41<00:00,  2.29s/it]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 239/239 [04:44<00:00,  1.19s/it]\n",
      "Applying ThemesExtractor: 100%|██████████| 254/254 [09:34<00:00,  2.26s/it]\n",
      "Applying NERExtractor: 100%|██████████| 254/254 [09:32<00:00,  2.25s/it]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:06<00:00,  2.33s/it]\n",
      "Generating Scenarios: 100%|██████████| 1/1 [00:33<00:00, 33.30s/it]\n",
      "Generating Samples: 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DSPy dataset: ragas_testset_single_hop.json\n",
      "Generating multi_hop testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor: 100%|██████████| 239/239 [09:35<00:00,  2.41s/it]\n",
      "Applying CustomNodeFilter:   0%|          | 0/254 [00:00<?, ?it/s]Node e7851736-b5ab-4dc0-8edd-dda5bf361911 does not have a summary. Skipping filtering.\n",
      "Node 4ff6d630-d8ee-4642-9975-888fd1979693 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   1%|          | 2/254 [00:04<08:56,  2.13s/it]Node fbeaddb3-c3ee-4687-96ff-5c088ca571f3 does not have a summary. Skipping filtering.\n",
      "Node 5e78e839-e1f8-424a-b5c5-f4c345b54c86 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 57/254 [02:35<06:23,  1.95s/it] Node 20ceb78b-e51a-4e88-a228-0c5e7ae71c0a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  30%|██▉       | 75/254 [03:14<05:13,  1.75s/it]Node 29167fc0-620c-45fc-8aa5-ef941415db0a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  37%|███▋      | 93/254 [03:53<04:30,  1.68s/it]Node d2bee3e9-7f9d-4d51-83e7-7d4d690909c1 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  37%|███▋      | 94/254 [04:24<10:05,  3.78s/it]Node 61e2c48b-c773-4ad2-8cee-a0b904ecb0c9 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  44%|████▍     | 112/254 [04:30<03:39,  1.55s/it]Node 56c2ba0b-c4dc-44a7-bcb4-7c1f500c67c1 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████     | 130/254 [05:08<03:19,  1.61s/it]Node c7d6fd1b-f3c8-496d-bc9e-adc355adbf16 does not have a summary. Skipping filtering.\n",
      "Node abed6d01-ec15-4cd7-bff3-39562965beee does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  86%|████████▌ | 218/254 [08:54<01:11,  2.00s/it]Node 9aa02081-dfe8-4fe4-b36e-da71901635c7 does not have a summary. Skipping filtering.\n",
      "Node 7d34c719-d8cb-4cd3-95a3-c9c2664e2135 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  93%|█████████▎| 236/254 [09:29<00:28,  1.60s/it]Node 82e3d060-b0d7-49d6-9f3b-8d0a5364b091 does not have a summary. Skipping filtering.\n",
      "Node 0d311b38-759c-4b28-931c-0f76b48fafa4 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter: 100%|██████████| 254/254 [10:04<00:00,  2.38s/it]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 239/239 [05:26<00:00,  1.37s/it]\n",
      "Applying ThemesExtractor: 100%|██████████| 254/254 [11:37<00:00,  2.74s/it]\n",
      "Applying NERExtractor: 100%|██████████| 254/254 [11:22<00:00,  2.69s/it]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Generating Scenarios: 100%|██████████| 2/2 [00:25<00:00, 12.85s/it]\n",
      "Generating Samples: 100%|██████████| 6/6 [00:16<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DSPy dataset: ragas_testset_multi_hop.json\n",
      "Generating mixed testset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor: 100%|██████████| 239/239 [09:19<00:00,  2.34s/it]\n",
      "Applying CustomNodeFilter:   0%|          | 0/254 [00:00<?, ?it/s]Node e3bbd6aa-4719-4132-9c58-5562f5c5bab3 does not have a summary. Skipping filtering.\n",
      "Node 0ae33412-9cd8-4750-8ce1-d103e214b285 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   1%|          | 2/254 [00:02<06:04,  1.45s/it]Node 1d1356f7-de11-4aff-ada3-f0d3e8a758e8 does not have a summary. Skipping filtering.\n",
      "Node f7dab48e-a594-4303-8999-69933708062f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  22%|██▏       | 56/254 [01:59<05:44,  1.74s/it]Node a0cfa895-6efe-4ace-a66e-bc667f2c236e does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  29%|██▉       | 74/254 [02:38<05:02,  1.68s/it]Node 6c968da0-5d56-41ab-af1b-9d40076d1343 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  36%|███▌      | 92/254 [03:18<04:36,  1.71s/it]Node 97d21a4f-28c7-42bd-8692-2f25e8a2742c does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 109/254 [03:52<03:46,  1.56s/it]Node 2992c602-2b9a-4702-bd9e-ee69b24e38f9 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  43%|████▎     | 110/254 [03:55<03:55,  1.63s/it]Node 80fcdde1-ed9d-4312-a93e-42989a332f30 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████     | 129/254 [04:34<03:20,  1.61s/it]Node f4f4bacf-7cd0-43d7-81e3-36a3a5da47ba does not have a summary. Skipping filtering.\n",
      "Node 435c91a0-326f-47e6-a2ca-7a723433aa6e does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  85%|████████▌ | 216/254 [07:48<01:06,  1.75s/it]Node ab645e81-ec8d-472e-9c32-145c04192d79 does not have a summary. Skipping filtering.\n",
      "Node 9b1beaa6-00f1-46f9-b2bc-60c02922b324 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  93%|█████████▎| 235/254 [08:27<00:30,  1.63s/it]Node b92824d3-d20a-444e-be19-f4150a931dc3 does not have a summary. Skipping filtering.\n",
      "Node 14633bc9-bd09-4fe9-9830-eddf396f0d5c does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter: 100%|██████████| 254/254 [09:05<00:00,  2.15s/it]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 239/239 [04:27<00:00,  1.12s/it]\n",
      "Applying ThemesExtractor: 100%|██████████| 254/254 [09:47<00:00,  2.31s/it]\n",
      "Applying NERExtractor: 100%|██████████| 254/254 [09:38<00:00,  2.28s/it]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:23<00:00,  7.96s/it]\n",
      "Generating Samples: 100%|██████████| 7/7 [00:17<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DSPy dataset: ragas_testset_mixed.json\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4917b27f9544e80a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###3. Defining RAG Agent",
   "id": "2dcae1593c598ead"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:12:56.049371Z",
     "start_time": "2025-12-18T19:12:56.044958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    loop_step: int\n",
    "    evaluation: str  # \"Sufficient\" or \"Insufficient\"\n",
    "    answer: str"
   ],
   "id": "2f8757f3b3b4fa77",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:12:56.794056Z",
     "start_time": "2025-12-18T19:12:56.788688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#3. Helper to get LLM from Config\n",
    "\n",
    "def get_llm(config: RunnableConfig) -> ChatOpenAI:\n",
    "    \"\"\"Extracts the LLM from the configuration.\"\"\"\n",
    "    configurable = config.get(\"configurable\", {})\n",
    "    llm = configurable.get(\"llm\")\n",
    "    if not llm:\n",
    "        raise ValueError(\"No LLM instance found in config. Please pass it via 'configurable'.\")\n",
    "    return llm\n",
    "\n",
    "def get_retriever(config: RunnableConfig):\n",
    "    \"\"\"Extracts the retriever from the configuration.\"\"\"\n",
    "    configurable = config.get(\"configurable\", {})\n",
    "    retriever = configurable.get(\"retriever\")\n",
    "    if not retriever:\n",
    "        raise ValueError(\"No 'retriever' found in config.\")\n",
    "    return retriever"
   ],
   "id": "22a587b0ecc4efd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:12:57.749245Z",
     "start_time": "2025-12-18T19:12:57.744211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Nodes - RAG Agent nodes\n",
    "def rewrite_query(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Rewrites the query if retrieval failed.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "\n",
    "    if loop_step == 0:\n",
    "        print(f\"---STEP {loop_step}: INITIAL QUERY PASS-THROUGH---\")\n",
    "        return {\"loop_step\": loop_step + 1}\n",
    "\n",
    "    print(f\"---STEP {loop_step}: REWRITING QUERY---\")\n",
    "\n",
    "    msg = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that optimizes queries for vector retrieval.\"),\n",
    "        HumanMessage(content=f\"Look at the initial question: {question}. Formulate an improved question to find better results.\")\n",
    "    ]\n",
    "    better_question = llm.invoke(msg).content\n",
    "\n",
    "    return {\"question\": better_question, \"loop_step\": loop_step + 1}"
   ],
   "id": "3fc6b25be66784f9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:13:03.371323Z",
     "start_time": "2025-12-18T19:13:03.365886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Retrieve documents using the injected retriever.\n",
    "    \"\"\"\n",
    "    retriever = get_retriever(config)  # <--- Get Retriever from config\n",
    "\n",
    "    print(\"---RETRIEVING DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Support both raw vector stores and dedicated retrievers\n",
    "    if hasattr(retriever, \"invoke\"):\n",
    "        # It's a standard LangChain Retriever\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "    elif hasattr(retriever, \"similarity_search\"):\n",
    "        # It's a VectorStore object (like Chroma)\n",
    "        retrieved_docs = retriever.similarity_search(question)\n",
    "    else:\n",
    "        raise ValueError(\"Injected object is neither a Retriever nor a VectorStore\")\n",
    "\n",
    "    return {\"documents\": retrieved_docs}"
   ],
   "id": "e24e43f64493c260",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:13:05.141969Z",
     "start_time": "2025-12-18T19:13:05.133526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Nodes - RAG Agent nodes\n",
    "def evaluator(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Evaluates if the retrieved documents are sufficient.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    print(\"---EVALUATING DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert evaluator. Given the context, determine if it is sufficient to answer the user question.\"),\n",
    "        (\"human\", \"Question: {question}\\n\\nContext: {context}\\n\\nIs the context sufficient? Return only 'YES' or 'NO'.\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    score = chain.invoke({\"question\": question, \"context\": docs_content})\n",
    "\n",
    "    status = \"Sufficient\" if \"YES\" in score.upper() else \"Insufficient\"\n",
    "    print(f\"---EVALUATION: {status}---\")\n",
    "    return {\"evaluation\": status}"
   ],
   "id": "c522502f36de5d29",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:13:05.939503Z",
     "start_time": "2025-12-18T19:13:05.933609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#4. Nodes - RAG Agent nodes\n",
    "\n",
    "def generate(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Generates the final answer.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    print(\"---GENERATING ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant. Use the context to answer the question. If you don't know, say so.\"),\n",
    "        (\"human\", \"Question: {question}\\n\\nContext: {context}\\n\\nAnswer:\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"question\": question, \"context\": docs_content})\n",
    "    return {\"answer\": answer}"
   ],
   "id": "144983a460994740",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:13:07.085327Z",
     "start_time": "2025-12-18T19:13:07.079414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Router (Unchanged)\n",
    "def router(state: State) -> Literal[\"generate\", \"rewrite_query\"]:\n",
    "    evaluation = state[\"evaluation\"]\n",
    "    loop_step = state[\"loop_step\"]\n",
    "    if evaluation == \"Sufficient\": return \"generate\"\n",
    "    if loop_step <= 3: return \"rewrite_query\"\n",
    "    return \"generate\""
   ],
   "id": "38901a06b29701ed",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:13:08.412151Z",
     "start_time": "2025-12-18T19:13:08.396627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. Graph Construction\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"rewrite_query\", rewrite_query)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"evaluator\", evaluator)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.add_edge(START, \"rewrite_query\")\n",
    "workflow.add_edge(\"rewrite_query\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"evaluator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluator\",\n",
    "    router,\n",
    "    {\"rewrite_query\": \"rewrite_query\", \"generate\": \"generate\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()"
   ],
   "id": "96f27b1c0fd64a76",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:26:45.563684Z",
     "start_time": "2025-12-18T19:26:45.557194Z"
    }
   },
   "cell_type": "code",
   "source": "llm_engine",
   "id": "d1fe6443308d0fe3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x00000211C0E60510>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211C0E60770>, root_client=<openai.OpenAI object at 0x00000211C0E0B460>, root_async_client=<openai.AsyncOpenAI object at 0x00000211C0E0B570>, model_name='gpt-4o-mini', temperature=0.01, model_kwargs={}, openai_api_key=SecretStr('**********'), request_timeout=180, stream_usage=True, n=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:15:48.974016Z",
     "start_time": "2025-12-18T19:15:44.110758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Execution with Injected LLM\n",
    "# B. Prepare Retriever (Setup Chroma)\n",
    "\n",
    "# Convert vector store to a standard retriever interface\n",
    "my_retriever = chromaVectorStore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# C. Invoke with Injection\n",
    "initial_input = {\"question\": \"What is the role of signatures in DSPY?\", \"loop_step\": 0}\n",
    "\n",
    "result = app.invoke(\n",
    "    initial_input,\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"llm\": llm_engine,\n",
    "            \"retriever\": my_retriever\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"answer\"])"
   ],
   "id": "459e1d1807d6f43f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "\n",
      "Final Answer:\n",
      "In DSPY, signatures play a crucial role in defining the structure of inputs and outputs for interactions with language models. They provide clear definitions that enhance type safety, automatic validation, and model portability. Signatures allow developers to work independently by introducing new fields as requirements evolve, making them team-friendly and reducing the complexity of managing shared prompt templates. Additionally, signatures enable DSPY to automatically optimize prompts based on the provided data, which is particularly beneficial as applications grow in complexity. Overall, signatures help maintain clarity and organization in the programming process while facilitating effective communication with language models.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#",
   "id": "677d5db711241fa9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "395b03e0a83e3a5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d64837bf1d6f9066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8be5f3b3737c1483"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Evaluating the RAG Agent",
   "id": "8e57aa1546d7e95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:39:05.178352Z",
     "start_time": "2025-12-18T19:39:05.171582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Step 9: Evaluate with Ragas & MLflow\n",
    "# ==========================================\n",
    "def evaluate_langgraph_agent(app, testsets_generator, appConfig):\n",
    "    \"\"\"Evaluates the LangGraph app using Ragas and logs to MLflow.\"\"\"\n",
    "\n",
    "    # Ragas Metrics\n",
    "    metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "\n",
    "    # Iterate over generated testsets\n",
    "    for name, test_df in testsets_generator:\n",
    "        print(f\"\\n--- Evaluating Testset: {name} ---\")\n",
    "\n",
    "        # Start MLflow Run\n",
    "        with mlflow.start_run(run_name=f\"RAG_Eval_{name}\"):\n",
    "            log_params({\"testset_type\": name, \"model\": \"gpt-4o\", \"vector_db\": \"Chroma\"})\n",
    "\n",
    "            questions = test_df['user_input'].tolist()\n",
    "            ground_truths = test_df['reference'].tolist()\n",
    "\n",
    "            answers = []\n",
    "            contexts = []\n",
    "\n",
    "            # Run Inference\n",
    "            for q in questions:\n",
    "                # Invoke LangGraph\n",
    "                print(q)\n",
    "                result = app.invoke({\"question\": q}, config=appConfig)\n",
    "\n",
    "                answers.append(result[\"answer\"])\n",
    "                # Extract page content for Ragas\n",
    "                retrieved_texts = [doc.page_content for doc in result[\"documents\"]]\n",
    "                contexts.append(retrieved_texts)\n",
    "\n",
    "            # Prepare Ragas Dataset\n",
    "            eval_data = {\n",
    "                \"question\": questions,\n",
    "                \"answer\": answers,\n",
    "                \"contexts\": contexts,\n",
    "                \"ground_truth\": ground_truths\n",
    "            }\n",
    "            dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "            # Run Evaluation\n",
    "            results = evaluate(\n",
    "                dataset,\n",
    "                metrics=metrics,\n",
    "                llm=LangchainLLMWrapper(llm_engine),\n",
    "                embeddings=LangchainEmbeddingsWrapper(embedding_engine)\n",
    "            )\n",
    "\n",
    "            print(f\"Results for {name}: {results}\")\n",
    "\n",
    "            # Log Metrics to MLflow\n",
    "            for metric_name, score in results.items():\n",
    "                log_metrics({metric_name: score})\n",
    "\n",
    "            # Save CSV artifact\n",
    "            csv_name = f\"eval_results_{name}.csv\"\n",
    "            results.to_pandas().to_csv(csv_name, index=False)\n",
    "            mlflow.log_artifact(csv_name)\n"
   ],
   "id": "c10902f8814b0524",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T19:39:06.762506Z",
     "start_time": "2025-12-18T19:39:06.747330Z"
    }
   },
   "cell_type": "code",
   "source": " datasetDFLs[0].head()",
   "id": "c74c0054e302f1d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the purpose of Ollama in the setup pro...   \n",
       "1  What role do metrics play in evaluating softwa...   \n",
       "2  What is DSPy and how it used in MLflow for emb...   \n",
       "3  What is an Artificial Neural Network and how i...   \n",
       "4  How does disinformation impact the development...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Table of Contents\\nChapter 1: DSPy - From Pro...   \n",
       "1  [Composition Patterns . . . . . . . . . . . . ...   \n",
       "2  [MLflow Setup and Installation . . . . . . . ....   \n",
       "3  [General purpose reranker models (small & effi...   \n",
       "4  [Chatbot . . . . . . . . . . . . . . . . . . ....   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Ollama is part of the setup process, specifica...   \n",
       "1  Metrics are essential in evaluating software a...   \n",
       "2  DSPy is mentioned in the context of embeddings...   \n",
       "3  An Artificial Neural Network is a computationa...   \n",
       "4  Disinformation can significantly hinder the de...   \n",
       "\n",
       "               persona_name      query_style query_length  \\\n",
       "0  AI Application Developer  PERFECT_GRAMMAR        SHORT   \n",
       "1        Software Architect  WEB_SEARCH_LIKE       MEDIUM   \n",
       "2        Software Architect     POOR_GRAMMAR         LONG   \n",
       "3        Software Architect  WEB_SEARCH_LIKE       MEDIUM   \n",
       "4  AI Application Developer  PERFECT_GRAMMAR         LONG   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of Ollama in the setup pro...</td>\n",
       "      <td>[Table of Contents\\nChapter 1: DSPy - From Pro...</td>\n",
       "      <td>Ollama is part of the setup process, specifica...</td>\n",
       "      <td>AI Application Developer</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What role do metrics play in evaluating softwa...</td>\n",
       "      <td>[Composition Patterns . . . . . . . . . . . . ...</td>\n",
       "      <td>Metrics are essential in evaluating software a...</td>\n",
       "      <td>Software Architect</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is DSPy and how it used in MLflow for emb...</td>\n",
       "      <td>[MLflow Setup and Installation . . . . . . . ....</td>\n",
       "      <td>DSPy is mentioned in the context of embeddings...</td>\n",
       "      <td>Software Architect</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is an Artificial Neural Network and how i...</td>\n",
       "      <td>[General purpose reranker models (small &amp; effi...</td>\n",
       "      <td>An Artificial Neural Network is a computationa...</td>\n",
       "      <td>Software Architect</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does disinformation impact the development...</td>\n",
       "      <td>[Chatbot . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>Disinformation can significantly hinder the de...</td>\n",
       "      <td>AI Application Developer</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-18T19:39:07.602139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Executing RAGAS Evaluation\n",
    "evalConfig={\n",
    "        \"configurable\": {\n",
    "            \"llm\": llm_engine,\n",
    "            \"retriever\": my_retriever\n",
    "        }\n",
    "    }\n",
    "\n",
    "testsetLs  = [(\"synthetic\", datasetDFLs[0])]\n",
    "evaluate_langgraph_agent(app, testsetLs, evalConfig)"
   ],
   "id": "697e90ea6a0515dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Testset: synthetic ---\n",
      "What is the purpose of Ollama in the setup process?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "What role do metrics play in evaluating software architecture?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 1: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 2: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 3: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---GENERATING ANSWER---\n",
      "What is DSPy and how it used in MLflow for embedding and retrieval?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "What is an Artificial Neural Network and how is it relevant in the context of AI?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "How does disinformation impact the development and deployment of AI applications, particularly in the context of ensuring secure integration and monitoring?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 1: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 2: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 3: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---GENERATING ANSWER---\n",
      "What is machne lerning?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 1: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "What is a Meta Prompt in the context of data analysis?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 1: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 2: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---STEP 3: REWRITING QUERY---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Insufficient---\n",
      "---GENERATING ANSWER---\n",
      "What is the significance of Safety Evaluation in the context of Reinforcement Learning?\n",
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ffb403325a1ac083"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dffb4895922b095a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#",
   "id": "50869672a3a55bbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
