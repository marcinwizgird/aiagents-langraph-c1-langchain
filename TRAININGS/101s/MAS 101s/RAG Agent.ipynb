{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:20:27.855128Z",
     "start_time": "2025-12-18T17:20:27.849059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import List, Literal, TypedDict\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableConfig"
   ],
   "id": "39404fd751a1a300",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "load_dotenv()",
   "id": "a3e824272f3753b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T14:30:54.517623Z",
     "start_time": "2025-12-18T14:30:54.514134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "PDF_PATH = \"xx.pdf\"\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "#COLLECTION_NAME = \"dspy_book_collection\"\n",
    "COLLECTION_NAME = \"rag_test_collection\""
   ],
   "id": "b4eab6783a67c44",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:03:24.551953Z",
     "start_time": "2025-12-18T17:03:23.334182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Global Models\n",
    "llm_engine = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embedding_engine = OpenAIEmbeddings()\n",
    "\n",
    "lm_judge = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    ")"
   ],
   "id": "6169d9cea4d37c40",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f8619337aee53e1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:03:25.989016Z",
     "start_time": "2025-12-18T17:03:25.898385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=COLLECTION_NAME,  # Must match the original collection name\n",
    "    embedding_function = embedding_engine,\n",
    "    persist_directory = CHROMA_PERSIST_DIR   # The directory where data was saved\n",
    ")\n",
    "\n",
    "# Now you can run searches immediately without re-adding documents\n",
    "# results = vector_store.similarity_search(\"What is the open source model?\")"
   ],
   "id": "69a344e19100b072",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:03:31.187381Z",
     "start_time": "2025-12-18T17:03:31.177339Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store._collection.count()",
   "id": "532a7c6503ee0ecd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T14:25:55.802267Z",
     "start_time": "2025-12-18T14:25:55.745834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import chromadb\n",
    "\n",
    "#client = chromadb.PersistentClient(CHROMA_PERSIST_DIR)  # Use your actual path\n",
    "\n",
    "# 2. Get the collection\n",
    "#collection = client.get_collection(COLLECTION_NAME)\n",
    "#data = collection.get(limit=10)"
   ],
   "id": "1b8fb46e28347819",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "604f2dba8d7d0418"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:05:09.486895Z",
     "start_time": "2025-12-18T17:05:08.473284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now you can run searches immediately without re-adding documents\n",
    "results = vector_store.similarity_search(\"DSPY\")"
   ],
   "id": "9dc0f05bdc067cd6",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:05:10.528726Z",
     "start_time": "2025-12-18T17:05:10.522961Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "b9c028cce40a2865",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Untitled', 'creationdate': '2025-12-14T17:21:32+05:00', 'page_label': '166', 'source': 'complete-book.pdf', 'moddate': '2025-12-14T17:21:29+05:00', 'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'page': 166, 'creator': '', 'total_pages': 254}, page_content='DSPy Embeddings and Retrieval\\nDSPy provides three components for semantic search:\\ndspy.Embedder\\nWraps embedding models to convert text into dense vectors where\\nsemantically similar text maps to nearby points. Supports two backends:\\n• Hosted models via LiteLLM (e.g., \"openai/text-embedding-3-small\")\\n• Custom Python callables: any function taking List[str] and returning a\\n2D float32 array, enabling local models like SentenceTransformer or\\nfully custom implementations.\\ndspy.retrievers.Embeddings\\nThe retrieval backend. Takes a document corpus and an embedder, converts\\ntexts to embeddings, and indexes them (e.g. FAISS for speed). Performs\\nnearest-neighbor search on queries and supports saving/loading indexed\\nembeddings. Register via dspy.settings.configure(rm=retriever).\\ndspy.Retrieve\\nA DSPy module that wraps the globally configured retrieval model\\n(dspy.settings.rm). Fetches relevant passages for a query, accepts k\\n(number of results), and returns a dspy.Prediction object. This abstraction\\ndecouples your module code from the retrieval implementation, allowing you\\nto swap between embeddings, BM25, or external APIs without code changes.\\nSeeing dspy.Embedder, dspy.retrievers.Embeddings and\\ndspy.Retrieve in action\\nimport dspy\\nfrom datasets import load_dataset\\nimport os\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\ndef load_corpus(n_questions=10000):\\n\\xa0   dataset = load_dataset(\"sentence-transformers/natural-questions\", split\\n=\"train\", streaming=True)  ①\\n\\xa0   subset = list(dataset.take(n_questions))\\n\\xa0   corpus = [item[\\'answer\\'] for item in subset if \\'answer\\' in item]\\n\\xa0   return subset, corpus\\ndef setup_dspy(corpus):\\n\\xa0   lm = dspy.LM(\"openai/gpt-3.5-turbo\")  ②\\n\\xa0   embedder = dspy.Embedder(\"openai/text-embedding-3-small\", dimensions=512)  ③\\n\\xa0   retriever = dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=3)\\n④\\n\\xa0   dspy.settings.configure(lm=lm, rm=retriever)  ⑤\\n166'),\n",
       " Document(metadata={'source': 'complete-book.pdf', 'moddate': '2025-12-14T17:21:29+05:00', 'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'creationdate': '2025-12-14T17:21:32+05:00', 'title': 'Untitled', 'total_pages': 254, 'page_label': '29', 'page': 29, 'creator': ''}, page_content='What’s Next?\\nThis chapter has introduced the foundational concepts of DSPy. The following\\nchapters will explore more advanced capabilities.\\nThe next chapter examines DSPy modules, both built-in and custom. We will\\nexplore powerful concepts like Chain of Thought, CodeAct, ReAct, and many\\nmore. These topics provide the knowledge needed to develop sophisticated AI\\napplications that can reason, generate code, process images, and execute\\ncomplex tasks autonomously.\\n29'),\n",
       " Document(metadata={'source': 'complete-book.pdf', 'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'total_pages': 254, 'page': 20, 'page_label': '20', 'creator': '', 'moddate': '2025-12-14T17:21:29+05:00', 'title': 'Untitled', 'creationdate': '2025-12-14T17:21:32+05:00'}, page_content='What have we accomplished?\\nYou have now gained an understanding of how to programmatically\\ncommunicate with LLMs via DSPy, with key takeaways being:\\n1. DSPy is Declarative: Focus on what you want, not how to prompt.\\n2. Signatures Define Structure : Clear input/output definitions are\\ncrucial.\\n3. dspy.Predict Handles Complexity : Let DSPy manage language model\\ninteractions.\\nFor developers accustomed to straightforward prompt templates with variable\\nsubstitution, the signature abstraction may initially seem unnecessarily\\ncomplex. While template strings work fine for simple cases, signatures excel\\nwhen applications grow. They provide type safety, automatic validation, model\\nportability, and most importantly, DSPy can automatically optimize prompts \\nbased on data.\\nIn practice, signatures are team-friendly. They allow developers to work\\nindependently by introducing new input or output fields as requirements\\nevolve. Additionally, resolving merge conflicts in shared prompt templates can\\nbe challenging.\\nSignatures offer additional capabilities that warrant deeper exploration.\\n20'),\n",
       " Document(metadata={'moddate': '2025-12-14T17:21:29+05:00', 'page_label': '30', 'total_pages': 254, 'page': 30, 'producer': 'Asciidoctor PDF 2.3.20, based on Prawn 2.4.0', 'creationdate': '2025-12-14T17:21:32+05:00', 'title': 'Untitled', 'source': 'complete-book.pdf', 'creator': ''}, page_content='Chapter 2: Core DSPy Modules\\nIntroduction\\nComplex AI tasks are rarely solved with a single prompt. They often involve\\nmultiple steps like retrieving information, thinking step-by-step, re-ranking\\ndocuments, and generating a final answer.\\nDSPy Modules act like \"Lego blocks\" for your LM program. You can define a\\nmodule for each distinct step (e.g., a SearchQueryGenerator module, a Retrieve\\nmodule, a SynthesizeAnswer module) and then compose them inside a larger\\ncustom module.\\nDSPy comes with several built-in modules — dspy.Predict is one of them. It\\nalso lets you subclass the dspy.Module base class to build your own custom\\nmodules.\\nFirst, we will create a custom DSPy Module.\\nCustom DSPy Module\\nEvery DSPy module inherits from the dspy.Module base class, which provides a\\nconsistent interface for composition, optimization, and execution.\\nA DSPy module typically has two key parts:\\nSignature: A simple, declarative line of code that defines what the module is\\nsupposed to do. It specifies the inputs (such as context and question) and the\\noutputs (such as answer). You are already familiar with DSPy signatures from\\nChapter 1.\\nforward method: The Python method that defines how the module executes its\\nlogic. In its simplest form, it is a single line that calls an LM (such as\\ndspy.Predict) using the defined signature.\\nThe following is a complete example of a custom module that uses a class-based\\nsignature to classify news articles.\\n30')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:06:30.444086Z",
     "start_time": "2025-12-18T17:06:30.438675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. State Definition\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    loop_step: int\n",
    "    evaluation: str  # \"Sufficient\" or \"Insufficient\"\n",
    "    answer: str"
   ],
   "id": "b54e07a49161d94c",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ff9d32df00f337d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:20:36.277381Z",
     "start_time": "2025-12-18T17:20:36.271799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#3. Helper to get LLM from Config\n",
    "\n",
    "def get_llm(config: RunnableConfig) -> ChatOpenAI:\n",
    "    \"\"\"Extracts the LLM from the configuration.\"\"\"\n",
    "    configurable = config.get(\"configurable\", {})\n",
    "    llm = configurable.get(\"llm\")\n",
    "    if not llm:\n",
    "        raise ValueError(\"No LLM instance found in config. Please pass it via 'configurable'.\")\n",
    "    return llm\n",
    "\n",
    "def get_retriever(config: RunnableConfig):\n",
    "    \"\"\"Extracts the retriever from the configuration.\"\"\"\n",
    "    configurable = config.get(\"configurable\", {})\n",
    "    retriever = configurable.get(\"retriever\")\n",
    "    if not retriever:\n",
    "        raise ValueError(\"No 'retriever' found in config.\")\n",
    "    return retriever"
   ],
   "id": "ebef57f744d52d40",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:20:44.105752Z",
     "start_time": "2025-12-18T17:20:44.100742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Nodes - RAG Agent nodes\n",
    "def rewrite_query(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Rewrites the query if retrieval failed.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "\n",
    "    if loop_step == 0:\n",
    "        print(f\"---STEP {loop_step}: INITIAL QUERY PASS-THROUGH---\")\n",
    "        return {\"loop_step\": loop_step + 1}\n",
    "\n",
    "    print(f\"---STEP {loop_step}: REWRITING QUERY---\")\n",
    "\n",
    "    msg = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that optimizes queries for vector retrieval.\"),\n",
    "        HumanMessage(content=f\"Look at the initial question: {question}. Formulate an improved question to find better results.\")\n",
    "    ]\n",
    "    better_question = llm.invoke(msg).content\n",
    "\n",
    "    return {\"question\": better_question, \"loop_step\": loop_step + 1}"
   ],
   "id": "87d6f6eb653b8e03",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:20:45.313758Z",
     "start_time": "2025-12-18T17:20:45.308345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Retrieve documents using the injected retriever.\n",
    "    \"\"\"\n",
    "    retriever = get_retriever(config)  # <--- Get Retriever from config\n",
    "\n",
    "    print(\"---RETRIEVING DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Support both raw vector stores and dedicated retrievers\n",
    "    if hasattr(retriever, \"invoke\"):\n",
    "        # It's a standard LangChain Retriever\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "    elif hasattr(retriever, \"similarity_search\"):\n",
    "        # It's a VectorStore object (like Chroma)\n",
    "        retrieved_docs = retriever.similarity_search(question)\n",
    "    else:\n",
    "        raise ValueError(\"Injected object is neither a Retriever nor a VectorStore\")\n",
    "\n",
    "    return {\"documents\": retrieved_docs}"
   ],
   "id": "895f04920a074e20",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:22:31.806152Z",
     "start_time": "2025-12-18T17:22:31.799524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Nodes - RAG Agent nodes\n",
    "def evaluator(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Evaluates if the retrieved documents are sufficient.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    print(\"---EVALUATING DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert evaluator. Given the context, determine if it is sufficient to answer the user question.\"),\n",
    "        (\"human\", \"Question: {question}\\n\\nContext: {context}\\n\\nIs the context sufficient? Return only 'YES' or 'NO'.\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    score = chain.invoke({\"question\": question, \"context\": docs_content})\n",
    "\n",
    "    status = \"Sufficient\" if \"YES\" in score.upper() else \"Insufficient\"\n",
    "    print(f\"---EVALUATION: {status}---\")\n",
    "    return {\"evaluation\": status}"
   ],
   "id": "e82c72a343475055",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:24:31.946897Z",
     "start_time": "2025-12-18T17:24:31.942099Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #4. Nodes - RAG Agent nodes\n",
    "\n",
    "def generate(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Generates the final answer.\n",
    "    \"\"\"\n",
    "    llm = get_llm(config) # <--- Get LLM from config\n",
    "\n",
    "    print(\"---GENERATING ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant. Use the context to answer the question. If you don't know, say so.\"),\n",
    "        (\"human\", \"Question: {question}\\n\\nContext: {context}\\n\\nAnswer:\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"question\": question, \"context\": docs_content})\n",
    "    return {\"answer\": answer}"
   ],
   "id": "15d8426af23f7704",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:24:32.663076Z",
     "start_time": "2025-12-18T17:24:32.658687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Router (Unchanged)\n",
    "def router(state: State) -> Literal[\"generate\", \"rewrite_query\"]:\n",
    "    evaluation = state[\"evaluation\"]\n",
    "    loop_step = state[\"loop_step\"]\n",
    "    if evaluation == \"Sufficient\": return \"generate\"\n",
    "    if loop_step <= 3: return \"rewrite_query\"\n",
    "    return \"generate\""
   ],
   "id": "b0f93cc6af240a59",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T17:24:35.120516Z",
     "start_time": "2025-12-18T17:24:35.105526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. Graph Construction\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"rewrite_query\", rewrite_query)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"evaluator\", evaluator)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.add_edge(START, \"rewrite_query\")\n",
    "workflow.add_edge(\"rewrite_query\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"evaluator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluator\",\n",
    "    router,\n",
    "    {\"rewrite_query\": \"rewrite_query\", \"generate\": \"generate\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()"
   ],
   "id": "c1cc4f6d4940a3b4",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T17:27:04.843598Z",
     "start_time": "2025-12-18T17:26:58.700671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Execution with Injected LLM\n",
    "# B. Prepare Retriever (Setup Chroma)\n",
    "\n",
    "# Convert vector store to a standard retriever interface\n",
    "my_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# C. Invoke with Injection\n",
    "initial_input = {\"question\": \"What is the role of signatures in DSPY?\", \"loop_step\": 0}\n",
    "\n",
    "result = app.invoke(\n",
    "    initial_input,\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"llm\": my_llm,\n",
    "            \"retriever\": my_retriever\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"answer\"])"
   ],
   "id": "c6ae465c70075416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---STEP 0: INITIAL QUERY PASS-THROUGH---\n",
      "---RETRIEVING DOCUMENTS---\n",
      "---EVALUATING DOCUMENTS---\n",
      "---EVALUATION: Sufficient---\n",
      "---GENERATING ANSWER---\n",
      "\n",
      "Final Answer:\n",
      "In DSPy, signatures play a crucial role in defining the structure of inputs and outputs for interactions with language models. They provide clear input/output definitions, which are essential for ensuring type safety, automatic validation, and model portability. Signatures help manage complexity by allowing developers to focus on what they want to achieve rather than how to prompt the model. They also facilitate team collaboration by enabling developers to introduce new fields as requirements evolve without causing conflicts in shared templates. Overall, signatures enhance the clarity and maintainability of the code while optimizing prompt generation based on data.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7fd8dea1d5b851a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
