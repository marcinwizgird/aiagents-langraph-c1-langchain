{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def create_cyclic_visualization(filename=\"cyclic_viz.png\"):\n",
    "    \"\"\"\n",
    "    Generates a simple Cyclic Graph diagram and saves it as an image.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    nodes = [\"Plan\", \"Act\", \"Evaluate\", \"Learn\"]\n",
    "    G.add_edges_from([\n",
    "        (\"Plan\", \"Act\"),\n",
    "        (\"Act\", \"Evaluate\"),\n",
    "        (\"Evaluate\", \"Learn\"),\n",
    "        (\"Learn\", \"Plan\"),  # The Cycle\n",
    "        (\"Evaluate\", \"End\") # The Exit\n",
    "    ])\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=3000, node_color='skyblue', edgecolors='black')\n",
    "\n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_family=\"sans-serif\", font_weight=\"bold\")\n",
    "\n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, width=2, arrowsize=20, arrowstyle='->', connectionstyle=\"arc3,rad=0.1\")\n",
    "\n",
    "    plt.title(\"Cyclic State Graph Pattern\", fontsize=15, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return filename\n",
    "\n",
    "def create_slide():\n",
    "    # 1. Create the Visualization first\n",
    "    img_path = create_cyclic_visualization()\n",
    "\n",
    "    # 2. Create Presentation\n",
    "    prs = Presentation()\n",
    "\n",
    "    # Use a blank layout (6) to have full control, or Title (0) / Title & Content (1)\n",
    "    # We will use a blank layout to arrange text on left and image on right manually\n",
    "    slide_layout = prs.slide_layouts[6]\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "\n",
    "    # --- ADD TITLE ---\n",
    "    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.4), Inches(9), Inches(1))\n",
    "    title_frame = title_box.text_frame\n",
    "    title_p = title_frame.add_paragraph()\n",
    "    title_p.text = \"Why LangGraph? The Need for Cyclic State Machines\"\n",
    "    title_p.font.size = Pt(32)\n",
    "    title_p.font.bold = True\n",
    "    title_p.font.name = 'Arial'\n",
    "\n",
    "    # --- ADD CONTENT (Left Side) ---\n",
    "    # Define text box dimensions\n",
    "    content_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(5.5), Inches(5.5))\n",
    "    tf = content_box.text_frame\n",
    "    tf.word_wrap = True\n",
    "\n",
    "    # Helper to add bullet points\n",
    "    def add_bullet(text_frame, text, level=0, bold=False, size=16):\n",
    "        p = text_frame.add_paragraph()\n",
    "        p.text = text\n",
    "        p.level = level\n",
    "        p.font.size = Pt(size)\n",
    "        p.font.name = 'Arial'\n",
    "        if bold:\n",
    "            p.font.bold = True\n",
    "        # Add a little spacing\n",
    "        p.space_before = Pt(6)\n",
    "        return p\n",
    "\n",
    "    # Section 1\n",
    "    add_bullet(tf, \"1. The Limitation of Linear Chains (DAGs)\", level=0, bold=True, size=18)\n",
    "    add_bullet(tf, \"Rigid Execution: Standard LLM chains follow a strict Input -> Step A -> Step B pipeline.\", level=1)\n",
    "    add_bullet(tf, \"Fragility: If one step fails, the entire chain breaks.\", level=1)\n",
    "    add_bullet(tf, \"No \\\"Retry\\\" Logic: Cannot naturally loop back to fix mistakes without restarting.\", level=1)\n",
    "\n",
    "    # Section 2\n",
    "    add_bullet(tf, \"2. The Solution: Cyclic State Graphs\", level=0, bold=True, size=18)\n",
    "    add_bullet(tf, \"Loops & Cycles: Agents can Plan -> Act -> Fail -> Learn -> Retry.\", level=1)\n",
    "    add_bullet(tf, \"Persistence (State): Shared memory persists across loops, remembering prior failures.\", level=1)\n",
    "    add_bullet(tf, \"Engineering Control: Replace prompt magic with code (Conditional Edges).\", level=1)\n",
    "\n",
    "    # Key Takeaway\n",
    "    p = tf.add_paragraph()\n",
    "    p.text = \"\\nKey Takeaway: Real agents need to iterate. LangGraph provides the architecture for iteration.\"\n",
    "    p.font.size = Pt(16)\n",
    "    p.font.bold = True\n",
    "    #p.font.color.rgb = 0x000000 # Black (or use RGBColor for custom)\n",
    "\n",
    "    # --- ADD IMAGE (Right Side) ---\n",
    "    # Adjust position to sit to the right of the text\n",
    "    slide.shapes.add_picture(img_path, Inches(6.2), Inches(2.0), width=Inches(3.5))\n",
    "\n",
    "    # --- SAVE ---\n",
    "    output_filename = \"LangGraph_Intro_Slide.pptx\"\n",
    "    prs.save(output_filename)\n",
    "    print(f\"Presentation saved as '{output_filename}'\")\n",
    "\n",
    "    # Cleanup the temporary image\n",
    "    if os.path.exists(img_path):\n",
    "        os.remove(img_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_slide()"
   ],
   "id": "677d6fa6752ef8f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Literal, TypedDict, Union\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# --- 1. CONFIGURATION & SCHEMA ---\n",
    "\n",
    "# A. Define the Structured Output Schema (The goal)\n",
    "class WeatherReport(BaseModel):\n",
    "    \"\"\"The final structured response we want.\"\"\"\n",
    "    city: str = Field(description=\"The city mentioned\")\n",
    "    temperature: str = Field(description=\"The temperature found\")\n",
    "    advice: str = Field(description=\"Clothing advice based on weather\")\n",
    "    confidence: int = Field(description=\"Confidence score 1-10\")\n",
    "\n",
    "# B. Define the State\n",
    "class AgentState(TypedDict):\n",
    "    # 'operator.add' appends new messages to the history rather than overwriting\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "\n",
    "# --- 2. DEFINE TOOLS ---\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a specific city.\"\"\"\n",
    "    # Mock data for demonstration\n",
    "    if \"warsaw\" in city.lower():\n",
    "        return \"It is rainy and 12Â°C.\"\n",
    "    elif \"sf\" in city.lower() or \"san francisco\" in city.lower():\n",
    "        return \"It is sunny and 22Â°C.\"\n",
    "    return \"Weather unknown.\"\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "# --- 3. DEFINE NODES ---\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Node 1: The Agent (Reasoning & Tool Selection)\n",
    "def agent_node(state: AgentState):\n",
    "    # Bind tools so the LLM knows it can use them\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Node 2: Tool Execution (Prebuilt by LangGraph)\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Node 3: Structured Formatter (The Final Step)\n",
    "def formatter_node(state: AgentState):\n",
    "    \"\"\"Takes the conversation history and generates the final JSON.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(WeatherReport)\n",
    "\n",
    "    # We summarize the entire conversation into the strict schema\n",
    "    prompt = \"Review the conversation history and generate the final report.\"\n",
    "    # We pass the history + the prompt\n",
    "    chain = structured_llm\n",
    "\n",
    "    # Invoke with the full message history\n",
    "    report = chain.invoke(state[\"messages\"] + [HumanMessage(content=prompt)])\n",
    "\n",
    "    # Return as a special AIMessage or just print it\n",
    "    # Here we return it as a message to store in history\n",
    "    return {\"messages\": [AIMessage(content=f\"FINAL_JSON: {report.json()}\")]}\n",
    "\n",
    "# --- 4. DEFINE EDGES (Logic) ---\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If the LLM called a tool, go to 'tools' node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    # If LLM is done (has text), go to 'formatter' to structure it\n",
    "    return \"formatter\"\n",
    "\n",
    "# --- 5. BUILD GRAPH ---\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"formatter\", formatter_node)\n",
    "\n",
    "# Set Entry\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add Edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"formatter\": \"formatter\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")     # Loop back: Agent -> Tools -> Agent\n",
    "workflow.add_edge(\"formatter\", END)     # Finish after formatting\n",
    "\n",
    "# --- 6. COMPILE WITH MEMORY ---\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# --- 7. RUN DEMONSTRATION ---\n",
    "\n",
    "# Config acts as the session ID\n",
    "config = {\"configurable\": {\"thread_id\": \"session_001\"}}\n",
    "\n",
    "print(\"--- Turn 1: User asks for weather (Triggers Tool) ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Check the weather in Warsaw.\")]}\n",
    "\n",
    "for event in app.stream(inputs, config=config):\n",
    "    for node, values in event.items():\n",
    "        # Print only the new messages added by the node\n",
    "        msg = values[\"messages\"][-1]\n",
    "        print(f\"ðŸ“ Node '{node}': {msg.content if isinstance(msg.content, str) else 'Tool Call'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "print(\"--- Turn 2: User asks follow up (Triggers Memory + Structured Output) ---\")\n",
    "# Note: We don't mention Warsaw again, but the agent remembers it from thread_id\n",
    "inputs_2 = {\"messages\": [HumanMessage(content=\"Is that cold? Generate the report.\")]}\n",
    "\n",
    "for event in app.stream(inputs_2, config=config):\n",
    "    for node, values in event.items():\n",
    "        msg = values[\"messages\"][-1]\n",
    "        print(f\"ðŸ“ Node '{node}': {msg.content}\")"
   ],
   "id": "1407555fa494679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_core.chains import LLMChain\n",
    "\n",
    "# Setup LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "# 1. Define the CoT Prompt [cite: 34]\n",
    "# The PDF example uses a math word problem about mangoes\n",
    "template = \"\"\"\n",
    "I went to the market and bought 20 mangoes.\n",
    "I gave 5 apples to the Ram and 3 to the Househelp.\n",
    "I then went and bought 12 more mangoes and ate 2.\n",
    "How many mangoes did I remain with?\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 2. Run the Chain\n",
    "chain = prompt | llm\n",
    "\n",
    "print(\"--- Chain of Thought Trace ---\")\n",
    "response = chain.invoke({})\n",
    "print(response.content)\n",
    "\n",
    "# Expected Trace (from PDF [cite: 43-49]):\n",
    "# \"Initial mangoes bought: You started with 20 mangoes.\n",
    "#  ...\n",
    "#  Now, you have 12 (initial) + 12 (additional) = 24 mangoes.\n",
    "#  Mangoes eaten: You ate 2 mangoes. Subtract 2 from the total: 24-2=22.\n",
    "#  So, after these steps, you have 22 mangoes remaining.\""
   ],
   "id": "79c9977a759aa1c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T21:56:19.158678Z",
     "start_time": "2025-12-14T21:31:09.979663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Note: Requires langchain-experimental package [cite: 9]\n",
    "from langchain_experimental.smart_llm import SmartLLMChain\n",
    "\n",
    "# Setup LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "# 1. Define the 'Hard Question' Prompt [cite: 260]\n",
    "hard_question = \"I have a 12 liter jug, a 4 liter jug and a 3 liter jug. I want to measure 6 liters. How do I do it?\"\n",
    "prompt = PromptTemplate.from_template(hard_question)\n",
    "\n",
    "# 2. Initialize SmartLLMChain (Tree of Thought) [cite: 263]\n",
    "# n_ideas=3 generates 3 branches of thought\n",
    "chain = SmartLLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    n_ideas=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- Tree of Thought (SmartLLM) Trace ---\")\n",
    "chain.run({})\n",
    "\n",
    "# Expected Trace (from PDF [cite: 280-468]):\n",
    "# Idea 1: Step 1: Fill 12L... Step 2: Pour into 4L...\n",
    "# Idea 2: ...\n",
    "# Idea 3: ...\n",
    "# Critique: Idea 1 seems correct... Idea 2 is not feasible because...\n",
    "# Final Answer: (Selects best path)"
   ],
   "id": "45eab3a3b223169a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tree of Thought (SmartLLM) Trace ---\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SmartLLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mI have a 12 liter jug, a 4 liter jug and a 3 liter jug. I want to measure 6 liters. How do I do it?\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_19744\\2082568738.py:23: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
      "  chain.run({})\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mConnectError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001B[39m, in \u001B[36mmap_httpcore_exceptions\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp.stream, typing.Iterable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_connections(closing)\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    235\u001B[39m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m236\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[32m    240\u001B[39m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    243\u001B[39m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m._connect_failed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._connection.handle_request(request)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m     77\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m78\u001B[39m     stream = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     80\u001B[39m     ssl_object = stream.get_extra_info(\u001B[33m\"\u001B[39m\u001B[33mssl_object\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001B[39m, in \u001B[36mHTTPConnection._connect\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mconnect_tcp\u001B[39m\u001B[33m\"\u001B[39m, logger, request, kwargs) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m     stream = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_backend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect_tcp\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m     trace.return_value = stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_backends\\sync.py:207\u001B[39m, in \u001B[36mSyncBackend.connect_tcp\u001B[39m\u001B[34m(self, host, port, timeout, local_address, socket_options)\u001B[39m\n\u001B[32m    202\u001B[39m exc_map: ExceptionMapping = {\n\u001B[32m    203\u001B[39m     socket.timeout: ConnectTimeout,\n\u001B[32m    204\u001B[39m     \u001B[38;5;167;01mOSError\u001B[39;00m: ConnectError,\n\u001B[32m    205\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    208\u001B[39m     sock = socket.create_connection(\n\u001B[32m    209\u001B[39m         address,\n\u001B[32m    210\u001B[39m         timeout,\n\u001B[32m    211\u001B[39m         source_address=source_address,\n\u001B[32m    212\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\contextlib.py:162\u001B[39m, in \u001B[36m_GeneratorContextManager.__exit__\u001B[39m\u001B[34m(self, typ, value, traceback)\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001B[39m, in \u001B[36mmap_exceptions\u001B[39m\u001B[34m(map)\u001B[39m\n\u001B[32m     13\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mConnectError\u001B[39m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mConnectError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\_base_client.py:982\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m    981\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m982\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    984\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_should_stream_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    985\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    986\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    987\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m httpx.TimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_client.py:914\u001B[39m, in \u001B[36mClient.send\u001B[39m\u001B[34m(self, request, stream, auth, follow_redirects)\u001B[39m\n\u001B[32m    912\u001B[39m auth = \u001B[38;5;28mself\u001B[39m._build_request_auth(request, auth)\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_client.py:942\u001B[39m, in \u001B[36mClient._send_handling_auth\u001B[39m\u001B[34m(self, request, auth, follow_redirects, history)\u001B[39m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_client.py:979\u001B[39m, in \u001B[36mClient._send_handling_redirects\u001B[39m\u001B[34m(self, request, follow_redirects, history)\u001B[39m\n\u001B[32m    977\u001B[39m     hook(request)\n\u001B[32m--> \u001B[39m\u001B[32m979\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_client.py:1014\u001B[39m, in \u001B[36mClient._send_single_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=request):\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     response = \u001B[43mtransport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, SyncByteStream)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_transports\\default.py:249\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    237\u001B[39m req = httpcore.Request(\n\u001B[32m    238\u001B[39m     method=request.method,\n\u001B[32m    239\u001B[39m     url=httpcore.URL(\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m     extensions=request.extensions,\n\u001B[32m    248\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m    250\u001B[39m     resp = \u001B[38;5;28mself\u001B[39m._pool.handle_request(req)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\contextlib.py:162\u001B[39m, in \u001B[36m_GeneratorContextManager.__exit__\u001B[39m\u001B[34m(self, typ, value, traceback)\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001B[39m, in \u001B[36mmap_httpcore_exceptions\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    117\u001B[39m message = \u001B[38;5;28mstr\u001B[39m(exc)\n\u001B[32m--> \u001B[39m\u001B[32m118\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m mapped_exc(message) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n",
      "\u001B[31mConnectError\u001B[39m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mAPIConnectionError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     15\u001B[39m chain = SmartLLMChain(\n\u001B[32m     16\u001B[39m     llm=llm,\n\u001B[32m     17\u001B[39m     prompt=prompt,\n\u001B[32m     18\u001B[39m     n_ideas=\u001B[32m3\u001B[39m,\n\u001B[32m     19\u001B[39m     verbose=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     20\u001B[39m )\n\u001B[32m     22\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m--- Tree of Thought (SmartLLM) Trace ---\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[43mchain\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[38;5;66;03m# Expected Trace (from PDF [cite: 280-468]):\u001B[39;00m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Idea 1: Step 1: Fill 12L... Step 2: Pour into 4L...\u001B[39;00m\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# Idea 2: ...\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# Idea 3: ...\u001B[39;00m\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# Critique: Idea 1 seems correct... Idea 2 is not feasible because...\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Final Answer: (Selects best path)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:188\u001B[39m, in \u001B[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    186\u001B[39m     warned = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    187\u001B[39m     emit_warning()\n\u001B[32m--> \u001B[39m\u001B[32m188\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_classic\\chains\\base.py:632\u001B[39m, in \u001B[36mChain.run\u001B[39m\u001B[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[39m\n\u001B[32m    630\u001B[39m         msg = \u001B[33m\"\u001B[39m\u001B[33m`run` supports only one positional argument.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    631\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m632\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[32m    633\u001B[39m         _output_key\n\u001B[32m    634\u001B[39m     ]\n\u001B[32m    636\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[32m    637\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001B[32m    638\u001B[39m         _output_key\n\u001B[32m    639\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:188\u001B[39m, in \u001B[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    186\u001B[39m     warned = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    187\u001B[39m     emit_warning()\n\u001B[32m--> \u001B[39m\u001B[32m188\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_classic\\chains\\base.py:413\u001B[39m, in \u001B[36mChain.__call__\u001B[39m\u001B[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[39m\n\u001B[32m    380\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[32m    381\u001B[39m \n\u001B[32m    382\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    404\u001B[39m \u001B[33;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[32m    405\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    406\u001B[39m config = {\n\u001B[32m    407\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcallbacks\u001B[39m\u001B[33m\"\u001B[39m: callbacks,\n\u001B[32m    408\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtags\u001B[39m\u001B[33m\"\u001B[39m: tags,\n\u001B[32m    409\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m    410\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m: run_name,\n\u001B[32m    411\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m413\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    414\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    415\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mRunnableConfig\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    416\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    417\u001B[39m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    418\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_classic\\chains\\base.py:167\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    165\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    166\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    168\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    169\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    170\u001B[39m     )\n\u001B[32m    172\u001B[39m     final_outputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    173\u001B[39m         inputs,\n\u001B[32m    174\u001B[39m         outputs,\n\u001B[32m    175\u001B[39m         return_only_outputs,\n\u001B[32m    176\u001B[39m     )\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_experimental\\smart_llm\\base.py:167\u001B[39m, in \u001B[36mSmartLLMChain._call\u001B[39m\u001B[34m(self, input_list, run_manager)\u001B[39m\n\u001B[32m    165\u001B[39m prompt, stop = \u001B[38;5;28mself\u001B[39m.prep_prompts(input_list, run_manager=run_manager)\n\u001B[32m    166\u001B[39m \u001B[38;5;28mself\u001B[39m.history.question = prompt.to_string()\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m ideas = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_ideate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    168\u001B[39m \u001B[38;5;28mself\u001B[39m.history.ideas = ideas\n\u001B[32m    169\u001B[39m critique = \u001B[38;5;28mself\u001B[39m._critique(stop, run_manager)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_experimental\\smart_llm\\base.py:269\u001B[39m, in \u001B[36mSmartLLMChain._ideate\u001B[39m\u001B[34m(self, stop, run_manager)\u001B[39m\n\u001B[32m    265\u001B[39m callbacks = run_manager.get_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    266\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m llm:\n\u001B[32m    267\u001B[39m     ideas = [\n\u001B[32m    268\u001B[39m         \u001B[38;5;28mself\u001B[39m._get_text_from_llm_result(\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m             \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    270\u001B[39m             step=\u001B[33m\"\u001B[39m\u001B[33mideate\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    271\u001B[39m         )\n\u001B[32m    272\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.n_ideas)\n\u001B[32m    273\u001B[39m     ]\n\u001B[32m    274\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, idea \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(ideas):\n\u001B[32m    275\u001B[39m         _colored_text = get_colored_text(idea, \u001B[33m\"\u001B[39m\u001B[33mblue\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1108\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1109\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1110\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1114\u001B[39m     **kwargs: Any,\n\u001B[32m   1115\u001B[39m ) -> LLMResult:\n\u001B[32m   1116\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    924\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    925\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    926\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m927\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    928\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    929\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    933\u001B[39m         )\n\u001B[32m    934\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    935\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1219\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1220\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1222\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1223\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1224\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1225\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1356\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1354\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mhttp_response\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1355\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1356\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1357\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1358\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1359\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1360\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1361\u001B[39m ):\n\u001B[32m   1362\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1351\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1344\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[32m   1345\u001B[39m             response,\n\u001B[32m   1346\u001B[39m             schema=original_schema_obj,\n\u001B[32m   1347\u001B[39m             metadata=generation_info,\n\u001B[32m   1348\u001B[39m             output_version=\u001B[38;5;28mself\u001B[39m.output_version,\n\u001B[32m   1349\u001B[39m         )\n\u001B[32m   1350\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1351\u001B[39m         raw_response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwith_raw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1352\u001B[39m         response = raw_response.parse()\n\u001B[32m   1353\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001B[39m, in \u001B[36mto_raw_response_wrapper.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    360\u001B[39m extra_headers[RAW_RESPONSE_HEADER] = \u001B[33m\"\u001B[39m\u001B[33mtrue\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    362\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mextra_headers\u001B[39m\u001B[33m\"\u001B[39m] = extra_headers\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    284\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m286\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1189\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1142\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1143\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1144\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1186\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   1187\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m   1188\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m1189\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1190\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1192\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1197\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1198\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1199\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1200\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1201\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1202\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1203\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1204\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1205\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1206\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1207\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1208\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_key\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_retention\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_retention\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1212\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1213\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msafety_identifier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1214\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1215\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1216\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1217\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1218\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1219\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1220\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1221\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1222\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1223\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1224\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1225\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1226\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mverbosity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1227\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1228\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1229\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m   1230\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m   1231\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1232\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1233\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1234\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m   1235\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1236\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1238\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1239\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\openai\\_base_client.py:1014\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1011\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m   1013\u001B[39m     log.debug(\u001B[33m\"\u001B[39m\u001B[33mRaising connection error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m APIConnectionError(request=request) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   1016\u001B[39m log.debug(\n\u001B[32m   1017\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mHTTP Response: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[33m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m'\u001B[39m,\n\u001B[32m   1018\u001B[39m     request.method,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     response.headers,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m log.debug(\u001B[33m\"\u001B[39m\u001B[33mrequest_id: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m, response.headers.get(\u001B[33m\"\u001B[39m\u001B[33mx-request-id\u001B[39m\u001B[33m\"\u001B[39m))\n",
      "\u001B[31mAPIConnectionError\u001B[39m: Connection error."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8d342b64caf89d7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
